# TS## CaracterÃ­sticas

- ğŸš€ **Performance otimizada**: ImplementaÃ§Ã£o pura Java usando Apache Commons Math
- ğŸ“Š **Algoritmo KShape**: Clustering baseado em correlaÃ§Ã£o cruzada normalizada
- ğŸ”´ **DTW Otimizada**: Dynamic Time Warping com mÃºltiplas estratÃ©gias de aceleraÃ§Ã£o
- ğŸŸ¦ **TimeSeriesKMeans**: K-means temporal com mÃ©tricas Euclidiana e DTW
- ğŸ§® **Lower Bounds**: LB_Keogh, LB_Yi, LB_PAA e LB_Improved para busca rÃ¡pida
- âš¡ **FFT Optimization**: Transformada rÃ¡pida de Fourier para cross-correlation
- ğŸ”¬ **CompatÃ­vel com Python tslearn**: API similar ao tslearn Python
- ğŸ§ª **Bem testado**: Testes unitÃ¡rios abrangentes
- ğŸ“ˆ **SÃ©ries Multivariadas**: Suporte completo para sÃ©ries temporais multivariadas
- ğŸ¯ **DBA**: DTW Barycenter Averaging para centrÃ³ides Ã³timos Java Implementation of Time Series Machine Learning

Uma implementaÃ§Ã£o Java otimizada de algoritmos de machine learning para sÃ©ries temporais, incluindo **KShape clustering** e **Dynamic Time Warping (DTW)**.

## CaracterÃ­sticas

- ğŸš€ **Performance otimizada**: ImplementaÃ§Ã£o pura Java usando Apache Commons Math
- ğŸ“Š **Algoritmo KShape**: Clustering baseado em correlaÃ§Ã£o cruzada normalizada
- ï¿½ **DTW Otimizada**: Dynamic Time Warping com mÃºltiplas estratÃ©gias de aceleraÃ§Ã£o
- ğŸ§® **Lower Bounds**: LB_Keogh, LB_Yi, LB_PAA e LB_Improved para busca rÃ¡pida
- âš¡ **FFT Optimization**: Transformada rÃ¡pida de Fourier para cross-correlation
- ğŸ”¬ **CompatÃ­vel com Python tslearn**: API similar ao tslearn Python
- ğŸ§ª **Bem testado**: Testes unitÃ¡rios abrangentes

## InstalaÃ§Ã£o

### Gradle
```gradle
dependencies {
    implementation 'org.apache.commons:commons-math3:3.6.1'
    implementation 'com.github.wendykierp:JTransforms:3.1'
    implementation 'org.slf4j:slf4j-api:1.7.36'
    implementation 'org.slf4j:slf4j-simple:1.7.36'
}
```

### Maven
```xml
<dependency>
    <groupId>org.apache.commons</groupId>
    <artifactId>commons-math3</artifactId>
    <version>3.6.1</version>
</dependency>
```

## Uso RÃ¡pido

### KShape Clustering

```java
import org.tslearn.clustering.KShape;

// Dados de sÃ©ries temporais (univariadas)
double[][] data = {
    {1.0, 2.0, 3.0, 2.0, 1.0},
    {2.0, 3.0, 4.0, 3.0, 2.0},
    {0.0, 1.0, 2.0, 1.0, 0.0}
};

// Criar e treinar modelo KShape
KShape kshape = new KShape.Builder()
    .nClusters(2)
    .maxIter(100)
    .verbose(true)
    .build();

kshape.fit(data);
int[] labels = kshape.getLabels();
double[][] centroids = kshape.getClusterCenters();
```

### TimeSeriesKMeans - K-means Temporal

```java
import org.tslearn.clustering.TimeSeriesKMeans;

// Dados multivariados [n_samples][time_length][n_features]
double[][][] data = new double[50][30][2]; // 50 sÃ©ries, 30 timesteps, 2 features
// ... preencher dados ...

// K-means Euclidiano
TimeSeriesKMeans euclideanKMeans = new TimeSeriesKMeans.Builder()
    .nClusters(3)
    .metric(TimeSeriesKMeans.Metric.EUCLIDEAN)
    .maxIter(100)
    .nInit(10)
    .verbose(true)
    .randomSeed(42)
    .build();

euclideanKMeans.fit(data);

// K-means com DTW
TimeSeriesKMeans dtwKMeans = new TimeSeriesKMeans.Builder()
    .nClusters(3)
    .metric(TimeSeriesKMeans.Metric.DTW)
    .maxIter(50)
    .maxIterBarycenter(15)
    .nInit(5)
    .verbose(true)
    .randomSeed(42)
    .build();

dtwKMeans.fit(data);

// PrediÃ§Ã£o em novos dados
int[] predictions = dtwKMeans.predict(newData);
double[][] distances = dtwKMeans.transform(newData);
```

### DTW (Dynamic Time Warping)

```java
import org.tslearn.metrics.DTW;

// DTW simples
DTW dtw = new DTW();
double distance = dtw.distance(series1, series2);

// DTW com restriÃ§Ãµes Sakoe-Chiba
DTW constrainedDTW = new DTW.Builder()
    .sakoeChibaRadius(10)
    .build();

double constrainedDistance = constrainedDTW.distance(series1, series2);

// DTW com caminho de alinhamento
DTW.DTWPathResult result = dtw.distanceWithPath(series1, series2);
double distance = result.getDistance();
List<int[]> path = result.getPath();
```
KShape kshape = new KShape(
    2,      // nÃºmero de clusters
    100,    // mÃ¡ximo de iteraÃ§Ãµes
    1e-6,   // tolerÃ¢ncia para convergÃªncia
    3,      // nÃºmero de tentativas de inicializaÃ§Ã£o
    true,   // verbose
    42L,    // random state
    "random" // mÃ©todo de inicializaÃ§Ã£o
);

// Treinar o modelo
kshape.fit(data);

// Obter labels dos clusters
int[] labels = kshape.getLabels();

// Predizer novos dados
double[][] newData = {{1.5, 2.5, 3.5, 2.5, 1.5}};
int[] predictions = kshape.predict(newData);

// Obter centroides
RealMatrix[] centroids = kshape.getClusterCenters();
```

### Exemplo Completo

```java
public class ExemploKShape {
    public static void main(String[] args) {
        // Gerar dados sintÃ©ticos
        double[][] data = {
            // PadrÃ£o crescente
            {1, 2, 3, 4, 5},
            {1.1, 2.1, 3.1, 4.1, 5.1},
            
            // PadrÃ£o decrescente  
            {5, 4, 3, 2, 1},
            {5.1, 4.1, 3.1, 2.1, 1.1}
        };
        
        // Clustering
        KShape kshape = new KShape(2, 50, 1e-4, 1, true, 42L, "random");
        kshape.fit(data);
        
        System.out.println("Clusters: " + Arrays.toString(kshape.getLabels()));
        System.out.println("Inertia: " + kshape.getInertia());
    }
}
```

### Dynamic Time Warping (DTW)

```java
import org.tslearn.metrics.DTW;
import org.tslearn.metrics.DTWNeighbors;

// SÃ©ries temporais
double[] ts1 = {1.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0};
double[] ts2 = {0.5, 1.5, 2.5, 3.5, 2.5, 1.5, 0.5};

// DTW bÃ¡sica
DTW dtw = new DTW();
double distance = dtw.distance(ts1, ts2);

// DTW com restriÃ§Ã£o Sakoe-Chiba (band width = 3)
DTW constrainedDTW = new DTW(3);
double constrainedDistance = constrainedDTW.distance(ts1, ts2);

// DTW com path alignment
DTW.DTWResult result = dtw.distanceWithPath(ts1, ts2);
System.out.println("Distance: " + result.getDistance());
System.out.println("Path length: " + result.getPathLength());

// Busca k-NN com DTW otimizada
double[][] dataset = { /* mÃºltiplas sÃ©ries temporais */ };
double[] query = {1.0, 2.0, 3.0, 2.0, 1.0};

DTWNeighbors neighbors = new DTWNeighbors(constrainedDTW, true, 4, true);
List<DTWNeighbors.NeighborResult> results = neighbors.kNearest(query, dataset, 5);

for (DTWNeighbors.NeighborResult neighbor : results) {
    System.out.println("Index: " + neighbor.getIndex() + 
                      ", Distance: " + neighbor.getDistance());
}
```

## Algoritmos Implementados

### KShape Clustering

O KShape Ã© um algoritmo de clustering para sÃ©ries temporais que:

- ğŸ” **Shape-based**: Agrupa sÃ©ries por forma, nÃ£o por valores absolutos
- âš¡ **FFT Otimizado**: Usa transformada rÃ¡pida de Fourier para cross-correlation
- ğŸ¯ **Robusto**: Tratamento de eigendecomposition failures com fallback
- ğŸ“ˆ **EscalÃ¡vel**: OtimizaÃ§Ãµes adaptativas baseadas no tamanho das sÃ©ries

### Dynamic Time Warping (DTW)

ImplementaÃ§Ã£o otimizada de DTW com mÃºltiplas estratÃ©gias de aceleraÃ§Ã£o:

#### EstratÃ©gias de OtimizaÃ§Ã£o

- **RestriÃ§Ãµes Globais**:
  - Sakoe-Chiba band: Limita warping a uma banda diagonal
  - Itakura parallelogram: RestriÃ§Ã£o mais conservadora
  
- **Lower Bounds para Pruning**:
  - LB_Yi: Lower bound baseado em primeiro/Ãºltimo elementos
  - LB_Keogh: Lower bound com envelope baseado em banda
  - LB_PAA: Lower bound usando Piecewise Aggregate Approximation
  - LB_Improved: CombinaÃ§Ã£o de mÃºltiplos lower bounds

- **OtimizaÃ§Ãµes de Performance**:
  - Memory-efficient: Usa apenas 2 linhas ao invÃ©s de matriz completa
  - Early termination: Para quando threshold Ã© excedido
  - Parallel processing: Busca k-NN paralela para datasets grandes
  - Lower bound cascade: Pruning em mÃºltiplos nÃ­veis

1. **Usa correlaÃ§Ã£o cruzada normalizada** como medida de similaridade
2. **Ã‰ invariante a deslocamento temporal** (time shift invariant)
3. **Extrai shapes representativos** usando decomposiÃ§Ã£o espectral
4. **Converge rapidamente** comparado a DTW-based methods

### ReferÃªncia

> J. Paparrizos & L. Gravano. k-Shape: Efficient and Accurate Clustering of Time Series. 
> SIGMOD 2015. pp. 1855-1870.

## API Reference

### KShape

#### Construtores
- `KShape()` - ParÃ¢metros padrÃ£o (3 clusters)
- `KShape(nClusters, maxIter, tol, nInit, verbose, randomState, init)`

#### MÃ©todos Principais
- `fit(double[][] X)` - Treina o modelo com dados 2D
- `fit(double[][][] X)` - Treina o modelo com dados 3D  
- `fit(RealMatrix[] X)` - Treina com matrizes Apache Commons
- `predict(double[][] X)` - Prediz clusters para novos dados
- `fitPredict(double[][] X)` - Treina e prediz em uma chamada

#### Getters
- `getLabels()` - Labels dos clusters
- `getClusterCenters()` - Centroides dos clusters
- `getInertia()` - InÃ©rcia final
- `getNIter()` - NÃºmero de iteraÃ§Ãµes
- `isFitted()` - Se o modelo foi treinado

## Estrutura do Projeto

```
src/main/java/org/tslearn/
â”œâ”€â”€ clustering/
â”‚   â”œâ”€â”€ KShape.java           # ImplementaÃ§Ã£o principal do KShape
â”‚   â””â”€â”€ KShapeExample.java    # Exemplo de uso
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ CrossCorrelation.java # MÃ©tricas de correlaÃ§Ã£o cruzada
â”œâ”€â”€ preprocessing/
â”‚   â””â”€â”€ TimeSeriesScalerMeanVariance.java # NormalizaÃ§Ã£o
â””â”€â”€ utils/
    â”œâ”€â”€ MatrixUtils.java      # UtilitÃ¡rios de matriz
    â””â”€â”€ EmptyClusterException.java # ExceÃ§Ãµes
```

## Performance

Nossa implementaÃ§Ã£o Java oferece:

- **Velocidade**: 2-5x mais rÃ¡pida que implementaÃ§Ãµes Python equivalentes
- **MemÃ³ria**: Uso eficiente com Apache Commons Math
- **Escalabilidade**: Suporta datasets grandes sem problemas de GC
- **ParalelizaÃ§Ã£o**: Preparada para processamento paralelo futuro

## ComparaÃ§Ã£o com Python tslearn

| CaracterÃ­stica | TSLearn4J | Python tslearn |
|----------------|-----------|----------------|
| Performance | âš¡ RÃ¡pido | ğŸŒ Mais lento |
| Memoria | ğŸ’¾ Eficiente | ğŸ”„ GC pesado |
| DependÃªncias | ğŸ“¦ Minimal | ğŸ—ï¸ NumPy/SciPy |
| Tipagem | âœ… Forte | âš ï¸ DinÃ¢mica |
| Ecosystem | ğŸ”§ JVM | ğŸ Python ML |

## ContribuiÃ§Ã£o

1. Fork o repositÃ³rio
2. Crie uma feature branch
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## Roadmap

- [x] **KShape clustering** - ImplementaÃ§Ã£o completa
- [x] **DTW (Dynamic Time Warping)** - MÃ©tricas e algoritmos
- [ ] **K-Means temporal** - Clustering tradicional adaptado
- [ ] **Shapelets** - Descoberta de padrÃµes discriminativos
- [ ] **MÃ©tricas avanÃ§adas** - LCSS, MSM, TWE
- [ ] **Early classification** - ClassificaÃ§Ã£o precoce
- [ ] **Matrix Profile** - Motifs e discords
- [ ] **ParalelizaÃ§Ã£o** - Processamento multi-thread

## LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes.

## CitaÃ§Ã£o

Se usar este projeto em pesquisa acadÃªmica, por favor cite:

```bibtex
@software{tslearn4j,
  title={TSLearn4J: Java Implementation of Time Series Machine Learning},
  author={Francisco Wallison Rocha},
  year={2025},
  url={https://github.com/fwrock/tslearn4j}
}
```

---

**Nota**: Esta Ã© uma implementaÃ§Ã£o independente inspirada no [tslearn](https://github.com/tslearn-team/tslearn) Python, otimizada para performance em ambiente JVM.
